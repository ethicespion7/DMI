{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muniques\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-9c88c6c5c5e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# Encode the feature values from strings to integers since the sklearn DecisionTreeClassifier only takes numerical values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \"\"\"\n\u001b[0;32m    239\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[0;32m    115\u001b[0m             types = sorted(t.__qualname__\n\u001b[0;32m    116\u001b[0m                            for t in set(type(v) for v in values))\n\u001b[1;32m--> 117\u001b[1;33m             raise TypeError(\"Encoders require their input to be uniformly \"\n\u001b[0m\u001b[0;32m    118\u001b[0m                             f\"strings or numbers. Got {types}\")\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Spyder Editor\n",
    "\n",
    "This is a temporary script file.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Create a Decision Stump\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "import scipy.stats as sps\n",
    "\n",
    "\n",
    "# Load in the data and define the column labels\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\"C:\\\\Users\\\\Chinmay\\\\Documents\\\\GitHub\\\\wireless_sensor_networks\\\\C2\\\\comaprision of X-MAC and cotinki-MAC\\\\mushroom_csv.csv\",header=None)\n",
    "dataset = dataset.sample(frac=1)\n",
    "dataset.columns = ['target','cap-shape','cap-surface','cap-color','bruises','odor','gill-attachment','gill-spacing',\n",
    "             'gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring',\n",
    "             'stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population',\n",
    "             'habitat']\n",
    "\n",
    "\n",
    "\n",
    "# Encode the feature values from strings to integers since the sklearn DecisionTreeClassifier only takes numerical values\n",
    "for label in dataset.columns:\n",
    "    dataset[label] = LabelEncoder().fit(dataset[label]).transform(dataset[label])\n",
    "\n",
    "    \n",
    "    \n",
    "Tree_model = DecisionTreeClassifier(criterion=\"entropy\",max_depth=1)\n",
    "\n",
    "\n",
    "X = dataset.drop('target',axis=1)\n",
    "Y = dataset['target'].where(dataset['target']==1,-1)\n",
    "\n",
    "\n",
    "\n",
    "predictions = np.mean(cross_validate(Tree_model,X,Y,cv=100)['test_score'])\n",
    "\n",
    "\n",
    "print('The accuracy is: ',predictions*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=100.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  99.95121951219512 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "import scipy.stats as sps\n",
    "\n",
    "\n",
    "# Load in the data and define the column labels\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(r\"C:\\Users\\Chinmay\\Documents\\GitHub\\wireless_sensor_networks\\C2\\comaprision of X-MAC and cotinki-MAC\\mushroom_csv.csv\",header=None)\n",
    "dataset = dataset.sample(frac=1)\n",
    "dataset.columns = ['target','cap-shape','cap-surface','cap-color','bruises','odor','gill-attachment','gill-spacing',\n",
    "             'gill-size','gill-color','stalk-shape','stalk-root','stalk-surface-above-ring','stalk-surface-below-ring','stalk-color-above-ring',\n",
    "             'stalk-color-below-ring','veil-type','veil-color','ring-number','ring-type','spore-print-color','population',\n",
    "             'habitat']\n",
    "\n",
    "\n",
    "\n",
    "# Encode the feature values from strings to integers since the sklearn DecisionTreeClassifier only takes numerical values\n",
    "for label in dataset.columns:\n",
    "    dataset[label] = LabelEncoder().fit(dataset[label].astype('str')).transform(dataset[label].astype('str'))\n",
    "int\n",
    "    \n",
    "    \n",
    "Tree_model = DecisionTreeClassifier(criterion=\"entropy\",max_depth=1)\n",
    "\n",
    "\n",
    "X = dataset.drop('target',axis=1)\n",
    "Y = dataset['target'].where(dataset['target']==1,-1)\n",
    "\n",
    "\n",
    "\n",
    "predictions = np.mean(cross_validate(Tree_model,X,Y,cv=100)['test_score'])\n",
    "\n",
    "\n",
    "print('The accuracy is: ',predictions*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a number of  50 base models we receive an accuracy of  99.95076923076923 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Boosting:\n",
    "\n",
    "    def __init__(self,dataset,T,test_dataset):\n",
    "        self.dataset = dataset\n",
    "        self.T = T\n",
    "        self.test_dataset = test_dataset\n",
    "        self.alphas = None\n",
    "        self.models = None\n",
    "        self.accuracy = []\n",
    "        self.predictions = None\n",
    "    \n",
    "    def fit(self):\n",
    "        # Set the descriptive features and the target feature\n",
    "        X = self.dataset.drop(['target'],axis=1)\n",
    "        Y = self.dataset['target'].where(self.dataset['target']==1,-1)\n",
    "\n",
    "        # Initialize the weights of each sample with wi = 1/N and create a dataframe in which the evaluation is computed\n",
    "        Evaluation = pd.DataFrame(Y.copy())\n",
    "        Evaluation['weights'] = 1/len(self.dataset) # Set the initial weights w = 1/N\n",
    "        \n",
    "\n",
    "        # Run the boosting algorithm by creating T \"weighted models\"\n",
    "        \n",
    "        alphas = [] \n",
    "        models = []\n",
    "        \n",
    "        for t in range(self.T):\n",
    "\n",
    "            # Train the Decision Stump(s)\n",
    "            Tree_model = DecisionTreeClassifier(criterion=\"entropy\",max_depth=1) # Mind the deth one --> Decision Stump\n",
    "            \n",
    "            # We know that we must train our decision stumps on weighted datasets where the weights depend on the results of\n",
    "            # the previous decision stumps. To accomplish that, we use the 'weights' column of the above created \n",
    "            # 'evaluation dataframe' together with the sample_weight parameter of the fit method.\n",
    "            # The documentation for the sample_weights parameter sais: \"[...] If None, then samples are equally weighted.\"\n",
    "            # Consequently, if NOT None, then the samples are NOT equally weighted and therewith we create a WEIGHTED dataset \n",
    "            # which is exactly what we want to have.\n",
    "            model = Tree_model.fit(X,Y,sample_weight=np.array(Evaluation['weights'])) \n",
    "            \n",
    "            # Append the single weak classifiers to a list which is later on used to make the \n",
    "            # weighted decision\n",
    "            models.append(model)\n",
    "            predictions = model.predict(X)\n",
    "            score = model.score(X,Y)\n",
    "\n",
    "            # Add values to the Evaluation DataFrame\n",
    "            Evaluation['predictions'] = predictions\n",
    "            Evaluation['evaluation'] = np.where(Evaluation['predictions'] == Evaluation['target'],1,0)\n",
    "            Evaluation['misclassified'] = np.where(Evaluation['predictions'] != Evaluation['target'],1,0)\n",
    "\n",
    "            # Calculate the misclassification rate and accuracy\n",
    "            accuracy = sum(Evaluation['evaluation'])/len(Evaluation['evaluation'])\n",
    "            misclassification = sum(Evaluation['misclassified'])/len(Evaluation['misclassified'])\n",
    "\n",
    "\n",
    "            # Caclulate the error\n",
    "            err = np.sum(Evaluation['weights']*Evaluation['misclassified'])/np.sum(Evaluation['weights'])\n",
    " \n",
    "   \n",
    "            # Calculate the alpha values\n",
    "            alpha = np.log((1-err)/err)\n",
    "            alphas.append(alpha)\n",
    "\n",
    "\n",
    "            # Update the weights wi --> These updated weights are used in the sample_weight parameter\n",
    "            # for the training of the next decision stump. \n",
    "            Evaluation['weights'] *= np.exp(alpha*Evaluation['misclassified'])\n",
    "\n",
    "            #print('The Accuracy of the {0}. model is : '.format(t+1),accuracy*100,'%')\n",
    "            #print('The missclassification rate is: ',misclassification*100,'%')\n",
    "        \n",
    "        self.alphas = alphas\n",
    "        self.models = models\n",
    "            \n",
    "    def predict(self):\n",
    "        X_test = self.test_dataset.drop(['target'],axis=1).reindex(range(len(self.test_dataset)))\n",
    "        Y_test = self.test_dataset['target'].reindex(range(len(self.test_dataset))).where(self.dataset['target']==1,-1)\n",
    "    \n",
    "        # With each model in the self.model list, make a prediction \n",
    "        \n",
    "        accuracy = []\n",
    "        predictions = []\n",
    "        \n",
    "        for alpha,model in zip(self.alphas,self.models):\n",
    "            prediction = alpha*model.predict(X_test) # We use the predict method for the single decisiontreeclassifier models in the list\n",
    "            predictions.append(prediction)\n",
    "            self.accuracy.append(np.sum(np.sign(np.sum(np.array(predictions),axis=0))==Y_test.values)/len(predictions[0]))\n",
    "            # The above line of code could be a little bit confusing and hence I will do up the single steps:\n",
    "            # Goal: Create a list of accuracies which can be used to plot the accuracy against the number of base learners used for the model\n",
    "            # 1. np.array(predictions) --> This is the array which contains the predictions of the single models. It has the shape 8124xn\n",
    "            # and hence looks like [[0.998,0.87,...0.87...],[...],[...],[0.99,1.23,...,1.05,0,99...]] \n",
    "            # 2. np.sum(np.array(predictions),axis=0) --> Summs up the first elements of the lists, that is 0,998+...+...+0.99. This is \n",
    "            # done since the formula for the prediction wants us to sum up the predictions of all models for each instance in the dataset. \n",
    "            # Hence if we have for example 3 models than the predictions array has the shape 8124x3 (Imagine a table with 3 columns and\n",
    "            # 8124 rows). Here the first column containst the predictions for the first model, the second column contains the \n",
    "            # prediction for the second model, the third column the prediction for the third model (mind that the\n",
    "            # second and third model are influenced by the results of the first resoectvely the first and the\n",
    "            # second model). This is logical since the results from column (model)\n",
    "            # n-1 are used to alter the weights of the nth model and the results of the nth model are then used to alter the weights\n",
    "            # of the n+1 model. \n",
    "            # 3. np.sign(np.sum(np.array(predictions),axis=0)) --> Since our test target data are elements of {-1,1} and we want to \n",
    "            # have our prediction in the same format, we use the sign function. Hence each column in the accuracy array is like\n",
    "            # [-0.998,1.002,1.24,...,-0.89] and each element represents the combined and weighted prediction of all models up this column\n",
    "            # (so if we are for instance in the 5th column and for the 4th instnace we find the value -0.989, this value represents the \n",
    "            # weighted prediction of a boosted model with 5 base learners for the 4th instance. The 4th instance of the 6th column represents\n",
    "            # the weighted and combined predictions of a boosted model with 6 base learners while the 4th instance of the 4th column represents\n",
    "            # the predction of a model with 4 base learners and so on and so forth...). To make a long story short, we are interested in the \n",
    "            # the sign of these comined predictions. If the sign is positive, we know that the true prediction is more likely postive (1) then\n",
    "            # negaive (-1). The higher the value (postive or negative) the more likely it is that the model returns the correct prediction.\n",
    "            # 4. np.sum(np.sign(np.sum(np.array(predictions),axis=0))==Y_test.values)/len(predictions[0]) --> With the last step we have transformed the array \n",
    "            # into the shape 8124x1 where the instances are elements {-1,1} and therewith we are now in the situation to compare this \n",
    "            # prediction with our target feature values. The target feature array is of the shape 8124x1 since for each row it contains\n",
    "            # exactly one prediction {-1,1} just as our just created array above --> Ready to compare ;).\n",
    "            # The comparison is done with the == Y_test.values command. As result we get an \n",
    "            # array of the shape 8124x1 where the instances are elements of {True,False} (True if our prediction is consistent with the \n",
    "            # target feature value and False if not). Since we want to calculate a percentage value we have to calculate the fraction of \n",
    "            # instances which have been classified correctly. Therefore we simply sum up the above comparison array \n",
    "            # with the elements {True,False} along the axis 0.\n",
    "            # and divide it by the total number of rows (8124) since True is the same as 1 and False is the same as 0. Hence correct predictions \n",
    "            # increase the sum while false predictions does not change the sum. If we predicted nothing correct the calculation is 0/8124 and \n",
    "            # therewith 0 and if we predicted everything correct, the calculation is 8124/8124 and thereiwth 1. \n",
    "            # 5. self.accuracy.append(np.sum(np.sign(np.sum(np.array(predictions),axis=0))==Y_test.values)/len(predictions[0])) -->\n",
    "            # After we have computed the above steps, we add the result to the self.accuracy list. This list has the shape n x 1, that is,\n",
    "            # for a model with 5 base learners this list has 5 entries where the 5th entry represents the accuracy of the model when all\n",
    "            # 5 base learners are combined, the 4th element the accuracy of the model when 4 base learners are combined and so on and so forth. This \n",
    "            # procedure has been explained above. That's it and we can plot the accuracy.\n",
    "        self.predictions = np.sign(np.sum(np.array(predictions),axis=0))\n",
    "\n",
    "   \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "######Plot the accuracy of the model against the number of stump-models used##########\n",
    "\n",
    "number_of_base_learners = 50\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax0 = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "for i in range(number_of_base_learners):\n",
    "    model = Boosting(dataset,i,dataset)\n",
    "    model.fit()\n",
    "    model.predict()\n",
    "\n",
    "ax0.plot(range(len(model.accuracy)),model.accuracy,'-b')\n",
    "ax0.set_xlabel('# models used for Boosting ')\n",
    "ax0.set_ylabel('accuracy')\n",
    "print('With a number of ',number_of_base_learners,'base models we receive an accuracy of ',model.accuracy[-1]*100,'%')    \n",
    "                 \n",
    "plt.show()        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  45.206153846153846 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "for label in dataset.columns:\n",
    "    dataset[label] = LabelEncoder().fit(dataset[label]).transform(dataset[label])\n",
    "    \n",
    "X = dataset.drop(['target'],axis=1)\n",
    "Y = dataset['target']\n",
    "\n",
    "#model = DecisionTreeClassifier(criterion='entropy',max_depth=1)\n",
    "#AdaBoost = AdaBoostClassifier(base_estimator= model,n_estimators=400,learning_rate=1)\n",
    "\n",
    "AdaBoost = AdaBoostClassifier(n_estimators=400,learning_rate=1,algorithm='SAMME')\n",
    "\n",
    "AdaBoost.fit(X,Y)\n",
    "\n",
    "prediction = AdaBoost.score(X,Y)\n",
    "\n",
    "print('The accuracy is: ',prediction*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
